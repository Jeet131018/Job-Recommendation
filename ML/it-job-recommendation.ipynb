{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Recommendations \n",
    "\n",
    "This notebook creates a model, to recommend job positions given a position requirements description . This is done only for IT jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:09.199538Z",
     "iopub.status.busy": "2023-06-25T01:40:09.199197Z",
     "iopub.status.idle": "2023-06-25T01:40:09.216694Z",
     "shell.execute_reply": "2023-06-25T01:40:09.215628Z",
     "shell.execute_reply.started": "2023-06-25T01:40:09.199488Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:09.218677Z",
     "iopub.status.busy": "2023-06-25T01:40:09.218269Z",
     "iopub.status.idle": "2023-06-25T01:40:10.222246Z",
     "shell.execute_reply": "2023-06-25T01:40:10.221271Z",
     "shell.execute_reply.started": "2023-06-25T01:40:09.218633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['jobpost', 'date', 'Title', 'Company', 'AnnouncementCode', 'Term',\n",
      "       'Eligibility', 'Audience', 'StartDate', 'Duration', 'Location',\n",
      "       'JobDescription', 'JobRequirment', 'RequiredQual', 'Salary',\n",
      "       'ApplicationP', 'OpeningDate', 'Deadline', 'Notes', 'AboutC', 'Attach',\n",
      "       'Year', 'Month', 'IT'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RequiredQual</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Title</th>\n",
       "      <th>JobDescription</th>\n",
       "      <th>JobRequirment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- University degree; economical background is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- Rendering technical assistance to Database M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>- Excellent knowledge of Windows 2000 Server, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Network Administrator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- Network monitoring and administration;\\r\\n- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>As a GD you are creative, innovative and have\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>The position of Graphic Designer (GD) demands ...</td>\n",
       "      <td>Graphic Designer will be responsible for every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Participants should be mid-level professionals...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic Analysis Workshop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>- Work experience of at least two years; \\r\\n-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Programmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         RequiredQual Eligibility  \\\n",
       "4   - University degree; economical background is ...         NaN   \n",
       "15  - Excellent knowledge of Windows 2000 Server, ...         NaN   \n",
       "19  As a GD you are creative, innovative and have\\...         NaN   \n",
       "34  Participants should be mid-level professionals...         NaN   \n",
       "35  - Work experience of at least two years; \\r\\n-...         NaN   \n",
       "\n",
       "                            Title  \\\n",
       "4              Software Developer   \n",
       "15          Network Administrator   \n",
       "19               Graphic Designer   \n",
       "34  Demographic Analysis Workshop   \n",
       "35                     Programmer   \n",
       "\n",
       "                                       JobDescription  \\\n",
       "4                                                 NaN   \n",
       "15                                                NaN   \n",
       "19  The position of Graphic Designer (GD) demands ...   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "\n",
       "                                        JobRequirment  \n",
       "4   - Rendering technical assistance to Database M...  \n",
       "15  - Network monitoring and administration;\\r\\n- ...  \n",
       "19  Graphic Designer will be responsible for every...  \n",
       "34                                                NaN  \n",
       "35                                                NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data job posts.csv/data job posts.csv')\n",
    "print(data.columns)\n",
    "# selecting only IT Jobs\n",
    "df = data[data['IT']]\n",
    "# selecting \n",
    "cols = ['RequiredQual', 'Eligibility', 'Title', 'JobDescription', 'JobRequirment']\n",
    "df=df[cols]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Job Titles\n",
    "Selecting only top 21 job titles, to manage class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:10.223887Z",
     "iopub.status.busy": "2023-06-25T01:40:10.223621Z",
     "iopub.status.idle": "2023-06-25T01:40:10.239128Z",
     "shell.execute_reply": "2023-06-25T01:40:10.238279Z",
     "shell.execute_reply.started": "2023-06-25T01:40:10.223841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Software Developer           134\n",
       "Web Developer                101\n",
       "Java Developer                88\n",
       "Graphic Designer              75\n",
       "Software Engineer             69\n",
       "Senior Java Developer         69\n",
       "PHP Developer                 65\n",
       "Senior Software Engineer      63\n",
       "Programmer                    56\n",
       "IT Specialist                 55\n",
       "Senior QA Engineer            43\n",
       "Senior Software Developer     41\n",
       "Android Developer             37\n",
       ".NET Developer                36\n",
       "Senior .NET Developer         34\n",
       "Senior PHP Developer          34\n",
       "iOS Developer                 31\n",
       "Software QA Engineer          29\n",
       "Senior Web Developer          29\n",
       "Database Developer            29\n",
       "Database Administrator        28\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['Title'].value_counts()[:21]\n",
    "keys = classes.keys().to_list()\n",
    "\n",
    "df = df[df['Title'].isin(keys)]\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change job titles to base title. For exmaple, chaning Senior Java Developer to Java Developer.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:10.241298Z",
     "iopub.status.busy": "2023-06-25T01:40:10.240912Z",
     "iopub.status.idle": "2023-06-25T01:40:10.256967Z",
     "shell.execute_reply": "2023-06-25T01:40:10.255952Z",
     "shell.execute_reply.started": "2023-06-25T01:40:10.241228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Java Developer          157\n",
       "Software Developer      134\n",
       "Software Engineer       132\n",
       "Web Developer           130\n",
       "PHP Developer            99\n",
       "Graphic Designer         75\n",
       "Software QA Engineer     72\n",
       ".NET Developer           70\n",
       "Database Admin/Dev       57\n",
       "Programmer               56\n",
       "IT Specialist            55\n",
       "Senior Web Developer     41\n",
       "Android Developer        37\n",
       "iOS Developer            31\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chane_titles(x):\n",
    "    x = x.strip()\n",
    "    if x == 'Senior Java Developer':\n",
    "        return 'Java Developer'\n",
    "    elif x == 'Senior Software Engineer':\n",
    "        return 'Software Engineer'\n",
    "    elif x == 'Senior QA Engineer':\n",
    "        return 'Software QA Engineer'\n",
    "    elif x == 'Senior Software Developer':\n",
    "        return 'Senior Web Developer'\n",
    "    elif x =='Senior PHP Developer':\n",
    "        return 'PHP Developer'\n",
    "    elif x == 'Senior .NET Developer':\n",
    "        return '.NET Developer'\n",
    "    elif x == 'Senior Web Developer':\n",
    "        return 'Web Developer'\n",
    "    elif x == 'Database Administrator':\n",
    "        return 'Database Admin/Dev'\n",
    "    elif x == 'Database Developer':\n",
    "        return 'Database Admin/Dev'\n",
    "\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "    \n",
    "df['Title'] = df['Title'].apply(chane_titles)\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building custom tokenizer to process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:10.261343Z",
     "iopub.status.busy": "2023-06-25T01:40:10.260724Z",
     "iopub.status.idle": "2023-06-25T01:40:10.282760Z",
     "shell.execute_reply": "2023-06-25T01:40:10.281763Z",
     "shell.execute_reply.started": "2023-06-25T01:40:10.261055Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        # lemmatize text - convert to base form \n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        # creating stopwords list, to ignore lemmatizing stopwords \n",
    "        self.stopwords = stopwords.words('english')\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.stopwords]\n",
    "\n",
    "# removing new line characters, and certain hypen patterns                  \n",
    "df['RequiredQual']=df['RequiredQual'].apply(lambda x: x.replace('\\n', ' ').replace('\\r', '').replace('- ', ''). replace(' - ', ' to '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:10.286900Z",
     "iopub.status.busy": "2023-06-25T01:40:10.286616Z",
     "iopub.status.idle": "2023-06-25T01:40:15.175318Z",
     "shell.execute_reply": "2023-06-25T01:40:15.174343Z",
     "shell.execute_reply.started": "2023-06-25T01:40:10.286849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayje\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\jayje\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['le', 'u'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# train features and labels \n",
    "y = df['Title']\n",
    "X = df['RequiredQual']\n",
    "# tdif feature rep \n",
    "vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')\n",
    "vectorizer.fit(X)\n",
    "# transoforming text to tdif features\n",
    "tfidf_matrix = vectorizer.transform(X)\n",
    "# sparse matrix to dense matrix for training\n",
    "X_tdif = tfidf_matrix.toarray()\n",
    "# encoding text labels in categories \n",
    "enc = LabelEncoder() \n",
    "enc.fit(y.values)\n",
    "y_enc=enc.transform(y.values)\n",
    "\n",
    "X_train_words, X_test_words, y_train, y_test = train_test_split(X, y_enc, test_size=0.15, random_state=10)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_words)\n",
    "X_train = X_train.toarray()\n",
    "\n",
    "X_test = vectorizer.transform(X_test_words)\n",
    "X_test = X_test.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Naive Bayes\n",
    "Looks pretty overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:15.187054Z",
     "iopub.status.busy": "2023-06-25T01:40:15.186680Z",
     "iopub.status.idle": "2023-06-25T01:40:15.475436Z",
     "shell.execute_reply": "2023-06-25T01:40:15.474470Z",
     "shell.execute_reply.started": "2023-06-25T01:40:15.186983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9455852156057495\n",
      "Test acc: 0.6918604651162791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "gnb = GaussianNB()\n",
    "train_preds = gnb.fit(X_train, y_train).predict(X_train)\n",
    "test_preds = gnb.predict(X_test)\n",
    "\n",
    "print('Train acc: {0}'.format(accuracy_score(y_train, train_preds)))\n",
    "print('Test acc: {0}'.format(accuracy_score(y_test, test_preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Logistic Regression\n",
    "By modifiying the maximum number of iterations, and regularization, C, the above experienced overfitting was reduced significantly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:15.477274Z",
     "iopub.status.busy": "2023-06-25T01:40:15.476911Z",
     "iopub.status.idle": "2023-06-25T01:40:15.615849Z",
     "shell.execute_reply": "2023-06-25T01:40:15.615219Z",
     "shell.execute_reply.started": "2023-06-25T01:40:15.477216Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8819301848049281\n",
      "Test acc: 0.7383720930232558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayje\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(max_iter=15,verbose=1, C=0.75)\n",
    "\n",
    "train_preds = logistic.fit(X_train, y_train).predict(X_train)\n",
    "test_preds = logistic.predict(X_test)\n",
    "\n",
    "print('Train acc: {0}'.format(accuracy_score(y_train, train_preds)))\n",
    "print('Test acc: {0}'.format(accuracy_score(y_test, test_preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T02:31:15.417009Z",
     "iopub.status.busy": "2023-06-25T02:31:15.416632Z",
     "iopub.status.idle": "2023-06-25T02:31:15.424630Z",
     "shell.execute_reply": "2023-06-25T02:31:15.423714Z",
     "shell.execute_reply.started": "2023-06-25T02:31:15.416957Z"
    }
   },
   "outputs": [],
   "source": [
    "#tpred = logistic.predict(tdata)\n",
    "#predicted_titles = enc.inverse_transform(tpred)\n",
    "#predicted_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:15.636144Z",
     "iopub.status.busy": "2023-06-25T01:40:15.635718Z",
     "iopub.status.idle": "2023-06-25T01:40:15.646403Z",
     "shell.execute_reply": "2023-06-25T01:40:15.645569Z",
     "shell.execute_reply.started": "2023-06-25T01:40:15.636056Z"
    }
   },
   "outputs": [],
   "source": [
    "#tpred_proba = logistic.predict_proba(tdata)\n",
    "#tpred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:15.648210Z",
     "iopub.status.busy": "2023-06-25T01:40:15.647920Z",
     "iopub.status.idle": "2023-06-25T01:40:15.659751Z",
     "shell.execute_reply": "2023-06-25T01:40:15.658614Z",
     "shell.execute_reply.started": "2023-06-25T01:40:15.648160Z"
    }
   },
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Job Recommendations \n",
    "Recommends 2 job position alternatives given a job requirement. By obtaining probability of class predictions, and picking the top N predictions, other than true label, N closest recommendations can be got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:15.661684Z",
     "iopub.status.busy": "2023-06-25T01:40:15.661241Z",
     "iopub.status.idle": "2023-06-25T01:40:15.699645Z",
     "shell.execute_reply": "2023-06-25T01:40:15.698880Z",
     "shell.execute_reply.started": "2023-06-25T01:40:15.661637Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T02:47:00.960788Z",
     "iopub.status.busy": "2023-06-25T02:47:00.960125Z",
     "iopub.status.idle": "2023-06-25T02:47:00.973730Z",
     "shell.execute_reply": "2023-06-25T02:47:00.972740Z",
     "shell.execute_reply.started": "2023-06-25T02:47:00.960719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual pred is [1]\n",
      "Predicted Job is:['Android Developer']\n",
      "[ 8  6  5  0 13 11 12  2  9  4  3 10  7  1]\n",
      "top class=[10  7]\n",
      "['Software Engineer' 'Programmer']\n"
     ]
    }
   ],
   "source": [
    "preds_data = {'Current Position Requirments': [], 'Current Position': [], 'Alternative 1': [], 'Alternative 2': []}\n",
    "tdata = vectorizer.transform([\"Fresher but developed various android apps\"])\n",
    "actual_pred = logistic.predict(tdata)\n",
    "print(f\"actual pred is {actual_pred}\")\n",
    "predicted_titles = enc.inverse_transform(actual_pred)\n",
    "print(f\"Predicted Job is:{predicted_titles}\")\n",
    "tpred = logistic.predict_proba(tdata)\n",
    "for i in tpred:\n",
    "    class_preds = np.argsort(i)\n",
    "    print(class_preds)\n",
    "    for i in [-1, -2]:\n",
    "        if class_preds[i] == actual_pred:\n",
    "            class_preds=np.delete(class_preds,i)\n",
    "    top_classes = class_preds[-2:]\n",
    "    print(f\"top class={top_classes}\")\n",
    "    class_names = enc.inverse_transform(top_classes)\n",
    "    print(class_names)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/label_encoder.pkl']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(logistic, 'models/logistic_regression_model.pkl')\n",
    "joblib.dump(vectorizer, 'models/tfidf_vectorizer.pkl')\n",
    "joblib.dump(enc, 'models/label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T01:40:15.701561Z",
     "iopub.status.busy": "2023-06-25T01:40:15.701138Z",
     "iopub.status.idle": "2023-06-25T01:40:15.718597Z",
     "shell.execute_reply": "2023-06-25T01:40:15.717455Z",
     "shell.execute_reply.started": "2023-06-25T01:40:15.701474Z"
    }
   },
   "outputs": [],
   "source": [
    "#preds_df = pd.DataFrame.from_dict(preds_data)\n",
    "#preds_df.to_csv('Recommendations.csv', index=False)\n",
    "#preds_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
